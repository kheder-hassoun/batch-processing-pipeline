Copy queries.txt Into HDFS
docker cp input-data/queries.txt namenode:/queries.txt

Then we put it into HDFS:
docker exec -it namenode hdfs dfs -mkdir -p /logs
docker exec -it namenode hdfs dfs -put /queries.txt /logs/
// or force put if its already existed
docker exec -it namenode hdfs dfs -put -f /queries.txt /logs/
then verify
docker exec -it namenode hdfs dfs -ls /logs
docker exec -it namenode hdfs dfs -cat /logs/queries.txt
*********************************************************************


docker exec -it spark-master /bin/bash
------------------------
//trending autocomplete approach
docker exec -it spark-master /bin/bash

/spark/bin/spark-submit  --master spark://spark-master:7077  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1  --class me.spark.TrendingAutocomplete   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/logs/queries.txt   mymongo.autocomplete_prefixes   5

//word count
/spark/bin/spark-submit   --master spark://spark-master:7077   --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1   --class me.spark.WordCount   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/input/sample.txt   mymongo.prefixcollection


-----------------------
view results
docker exec -it namenode hdfs dfs -ls /output
docker exec -it namenode hdfs dfs -cat /output/part-00000
********************  status   ****************
*** Spark
http://localhost:8080/


***data base
docker container exec -it mongodb mongosh
 show databases
use mymongo
show collections
db.prefixcollection.find()
