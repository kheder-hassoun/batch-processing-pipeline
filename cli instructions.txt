Copy sample.txt Into HDFS
docker cp input-data/sample.txt namenode:/sample.txt

Then we put it into HDFS:
docker exec -it namenode hdfs dfs -mkdir -p /input
docker exec -it namenode hdfs dfs -put /sample.txt /input/
then verify
docker exec -it namenode hdfs dfs -ls /input
docker exec -it namenode hdfs dfs -cat /input/sample.txt
*********************************************************************


docker exec -it spark-master /bin/bash
------------------------
//trending autocomplete approach
docker exec -it spark-master /bin/bash

/spark/bin/spark-submit  --master spark://spark-master:7077  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1  --class me.spark.TrendingAutocomplete   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/logs/queries.txt   mymongo.autocomplete_prefixes   5

//word count
/spark/bin/spark-submit   --master spark://spark-master:7077   --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1   --class me.spark.WordCount   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/input/sample.txt   mymongo.prefixcollection


-----------------------
view results
docker exec -it namenode hdfs dfs -ls /output
docker exec -it namenode hdfs dfs -cat /output/part-00000
********************  status   ****************
*** Spark
http://localhost:8080/


***data base
docker container exec -it mongodb mongosh
 show databases
use mymongo
show collections
db.prefixcollection.find()
