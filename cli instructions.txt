------------------------------final test ----------------------------
docker exec -it namenode hdfs dfs -cat /logs/queries.txt
docker exec -it spark-master /bin/bash
// run it separately due the stupid terminal doesn't accept the capital letters
  /spark/bin/spark-submit  --master spark://spark-master:7077  --class me.spark.TrendingAutocomplete  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0  /opt/spark-apps/spark-hdfs.jar  hdfs://namenode:8020/logs/queries.txt  kafka:9092  5

/// the last problem 14 may 2025
there is no class name TrendingAutocomplete // i got to menfist and fix it but think the problem is old jar in the conatiners so  i delete it .
in the next time you should add the text file agian to the hdfs after creat the containers





---------------------------------------------------------------------
Copy queries.txt Into HDFS
docker cp input-data/queries.txt namenode:/queries.txt

Then we put it into HDFS:
docker exec -it namenode hdfs dfs -mkdir -p /logs
docker exec -it namenode hdfs dfs -put /queries.txt /logs/
// or force put if its already existed
docker exec -it namenode hdfs dfs -put -f /queries.txt /logs/
then verify
docker exec -it namenode hdfs dfs -ls /logs
docker exec -it namenode hdfs dfs -cat /logs/queries.txt
*********************************************************************


docker exec -it spark-master /bin/bash
------------------------
//trending autocomplete approach
docker exec -it spark-master /bin/bash

/spark/bin/spark-submit  --master spark://spark-master:7077  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1  --class me.spark.TrendingAutocomplete   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/logs/queries.txt   mymongo.autocomplete_prefixes   5

//word count
/spark/bin/spark-submit   --master spark://spark-master:7077   --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1   --class me.spark.WordCount   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/input/sample.txt   mymongo.prefixcollection


-----------------------
view results
docker exec -it namenode hdfs dfs -ls /output
docker exec -it namenode hdfs dfs -cat /output/part-00000
********************  status   ****************
*** Spark
http://localhost:8080/


***data base
docker container exec -it mongodb mongosh
 show databases
use mymongo
show collections
db.prefixcollection.find()
