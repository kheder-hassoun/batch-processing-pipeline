------------------------------final test ----------------------------

docker exec -it namenode hdfs dfs -cat /logs/queries.txt
docker exec -it spark-master /bin/bash
// run it separately due the stupid terminal doesn't accept the capital letters
  /spark/bin/spark-submit  --master spark://spark-master:7077  --class me.spark.TrendingAutocomplete  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0  /opt/spark-apps/spark-hdfs.jar  hdfs://namenode:8020/logs/queries.txt  kafka:9092  5

run this in the kafka-tools
docker exec -it kafka-tools kafka-console-consumer --bootstrap-server kafka:9092  --topic autocomplete_prefixes --from-beginning

--- docker
docker compose down -v
docker compose down --volumes
docker compose build --no-cache policy-service
or
docker compose up -d






---------------------------------------------------------------------
Copy queries.txt Into HDFS
docker cp input-data/queries.txt namenode:/queries.txt

Then we put it into HDFS:
docker exec -it namenode hdfs dfs -mkdir -p /logs
docker exec -it namenode hdfs dfs -put /queries.txt /logs/
// or force put if its already existed
docker exec -it namenode hdfs dfs -put -f /queries.txt /logs/
then verify
docker exec -it namenode hdfs dfs -ls /logs
docker exec -it namenode hdfs dfs -cat /logs/queries.txt
*********************************************************************


docker exec -it spark-master /bin/bash
------------------------
//trending autocomplete approach
docker exec -it spark-master /bin/bash

/spark/bin/spark-submit  --master spark://spark-master:7077  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1  --class me.spark.TrendingAutocomplete   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/logs/queries.txt   mymongo.autocomplete_prefixes   5

//word count
/spark/bin/spark-submit   --master spark://spark-master:7077   --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1   --class me.spark.WordCount   /opt/spark-apps/spark-hdfs.jar   hdfs://namenode:8020/input/sample.txt   mymongo.prefixcollection


-----------------------
view results
docker exec -it namenode hdfs dfs -ls /output
docker exec -it namenode hdfs dfs -cat /output/part-00000
********************  status   ****************
*** Spark
http://localhost:8080/


***data base
docker container exec -it mongodb mongosh
 show databases
use mymongo
show collections
db.autocomplete_prefixes.find().pretty()

